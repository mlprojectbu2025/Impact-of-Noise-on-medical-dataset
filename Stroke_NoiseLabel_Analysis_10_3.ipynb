{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quytTvyv2Umi",
        "outputId": "6f1ea5f5-3612-44ef-d08a-8532b45816a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading stroke dataset...\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
            "0   9046    Male  67.0             0              1          Yes   \n",
            "1  51676  Female  61.0             0              0          Yes   \n",
            "2  31112    Male  80.0             0              1          Yes   \n",
            "3  60182  Female  49.0             0              0          Yes   \n",
            "4   1665  Female  79.0             1              0          Yes   \n",
            "\n",
            "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
            "0        Private          Urban             228.69  36.6  formerly smoked   \n",
            "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
            "2        Private          Rural             105.92  32.5     never smoked   \n",
            "3        Private          Urban             171.23  34.4           smokes   \n",
            "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
            "\n",
            "   stroke  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5110 entries, 0 to 5109\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 5110 non-null   int64  \n",
            " 1   gender             5110 non-null   object \n",
            " 2   age                5110 non-null   float64\n",
            " 3   hypertension       5110 non-null   int64  \n",
            " 4   heart_disease      5110 non-null   int64  \n",
            " 5   ever_married       5110 non-null   object \n",
            " 6   work_type          5110 non-null   object \n",
            " 7   Residence_type     5110 non-null   object \n",
            " 8   avg_glucose_level  5110 non-null   float64\n",
            " 9   bmi                4909 non-null   float64\n",
            " 10  smoking_status     5110 non-null   object \n",
            " 11  stroke             5110 non-null   int64  \n",
            "dtypes: float64(3), int64(4), object(5)\n",
            "memory usage: 479.2+ KB\n",
            "\n",
            "Missing Values in Each Column:\n",
            "id                     0\n",
            "gender                 0\n",
            "age                    0\n",
            "hypertension           0\n",
            "heart_disease          0\n",
            "ever_married           0\n",
            "work_type              0\n",
            "Residence_type         0\n",
            "avg_glucose_level      0\n",
            "bmi                  201\n",
            "smoking_status         0\n",
            "stroke                 0\n",
            "dtype: int64\n",
            "\n",
            "Class Distribution in Original Dataset:\n",
            "stroke\n",
            "0    4860\n",
            "1     249\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Evaluating each model under different noise levels (10 runs each)...\n",
            "\n",
            "=== Model: Logistic Regression ===\n",
            "Noise 0% - Iteration 1: Oversampled class distribution: [2430 2430]\n",
            "Noise 0% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=17937, FP=6363], [FN=256, TP=994]]\n",
            "   Accuracy: 74.09%, TPR: 79.52%, TNR: 73.81%\n",
            "Noise 5% - Iteration 1: Oversampled class distribution: [2311 2311]\n",
            "Noise 5% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=16180, FP=8120], [FN=182, TP=1068]]\n",
            "   Accuracy: 67.51%, TPR: 85.44%, TNR: 66.58%\n",
            "Noise 10% - Iteration 1: Oversampled class distribution: [2191 2191]\n",
            "Noise 10% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=15402, FP=8898], [FN=164, TP=1086]]\n",
            "   Accuracy: 64.53%, TPR: 86.88%, TNR: 63.38%\n",
            "Noise 15% - Iteration 1: Oversampled class distribution: [2065 2065]\n",
            "Noise 15% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=14680, FP=9620], [FN=189, TP=1061]]\n",
            "   Accuracy: 61.61%, TPR: 84.88%, TNR: 60.41%\n",
            "Noise 20% - Iteration 1: Oversampled class distribution: [1956 1956]\n",
            "Noise 20% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=14237, FP=10063], [FN=189, TP=1061]]\n",
            "   Accuracy: 59.87%, TPR: 84.88%, TNR: 58.59%\n",
            "Noise 25% - Iteration 1: Oversampled class distribution: [1838 1838]\n",
            "Noise 25% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13409, FP=10891], [FN=262, TP=988]]\n",
            "   Accuracy: 56.35%, TPR: 79.04%, TNR: 55.18%\n",
            "Noise 30% - Iteration 1: Oversampled class distribution: [1720 1720]\n",
            "Noise 30% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13018, FP=11282], [FN=368, TP=882]]\n",
            "   Accuracy: 54.40%, TPR: 70.56%, TNR: 53.57%\n",
            "Noise 35% - Iteration 1: Oversampled class distribution: [1603 1603]\n",
            "Noise 35% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13286, FP=11014], [FN=424, TP=826]]\n",
            "   Accuracy: 55.23%, TPR: 66.08%, TNR: 54.67%\n",
            "Noise 40% - Iteration 1: Oversampled class distribution: [1493 1493]\n",
            "Noise 40% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=12583, FP=11717], [FN=540, TP=710]]\n",
            "   Accuracy: 52.03%, TPR: 56.80%, TNR: 51.78%\n",
            "\n",
            "=== Model: Decision Tree ===\n",
            "Noise 0% - Iteration 1: Oversampled class distribution: [2430 2430]\n",
            "Noise 0% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=23271, FP=1029], [FN=1094, TP=156]]\n",
            "   Accuracy: 91.69%, TPR: 12.48%, TNR: 95.77%\n",
            "Noise 5% - Iteration 1: Oversampled class distribution: [2311 2311]\n",
            "Noise 5% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=22148, FP=2152], [FN=1059, TP=191]]\n",
            "   Accuracy: 87.43%, TPR: 15.28%, TNR: 91.14%\n",
            "Noise 10% - Iteration 1: Oversampled class distribution: [2191 2191]\n",
            "Noise 10% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=21082, FP=3218], [FN=978, TP=272]]\n",
            "   Accuracy: 83.58%, TPR: 21.76%, TNR: 86.76%\n",
            "Noise 15% - Iteration 1: Oversampled class distribution: [2065 2065]\n",
            "Noise 15% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=19945, FP=4355], [FN=948, TP=302]]\n",
            "   Accuracy: 79.24%, TPR: 24.16%, TNR: 82.08%\n",
            "Noise 20% - Iteration 1: Oversampled class distribution: [1956 1956]\n",
            "Noise 20% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=18697, FP=5603], [FN=881, TP=369]]\n",
            "   Accuracy: 74.62%, TPR: 29.52%, TNR: 76.94%\n",
            "Noise 25% - Iteration 1: Oversampled class distribution: [1838 1838]\n",
            "Noise 25% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=17562, FP=6738], [FN=837, TP=413]]\n",
            "   Accuracy: 70.35%, TPR: 33.04%, TNR: 72.27%\n",
            "Noise 30% - Iteration 1: Oversampled class distribution: [1720 1720]\n",
            "Noise 30% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=16433, FP=7867], [FN=790, TP=460]]\n",
            "   Accuracy: 66.12%, TPR: 36.80%, TNR: 67.63%\n",
            "Noise 35% - Iteration 1: Oversampled class distribution: [1603 1603]\n",
            "Noise 35% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=15303, FP=8997], [FN=735, TP=515]]\n",
            "   Accuracy: 61.91%, TPR: 41.20%, TNR: 62.98%\n",
            "Noise 40% - Iteration 1: Oversampled class distribution: [1493 1493]\n",
            "Noise 40% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=14161, FP=10139], [FN=708, TP=542]]\n",
            "   Accuracy: 57.55%, TPR: 43.36%, TNR: 58.28%\n",
            "\n",
            "=== Model: Random Forest ===\n",
            "Noise 0% - Iteration 1: Oversampled class distribution: [2430 2430]\n",
            "Noise 0% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=24050, FP=250], [FN=1217, TP=33]]\n",
            "   Accuracy: 94.26%, TPR: 2.64%, TNR: 98.97%\n",
            "Noise 5% - Iteration 1: Oversampled class distribution: [2311 2311]\n",
            "Noise 5% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=23813, FP=487], [FN=1180, TP=70]]\n",
            "   Accuracy: 93.48%, TPR: 5.60%, TNR: 98.00%\n",
            "Noise 10% - Iteration 1: Oversampled class distribution: [2191 2191]\n",
            "Noise 10% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=23312, FP=988], [FN=1138, TP=112]]\n",
            "   Accuracy: 91.68%, TPR: 8.96%, TNR: 95.93%\n",
            "Noise 15% - Iteration 1: Oversampled class distribution: [2065 2065]\n",
            "Noise 15% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=22631, FP=1669], [FN=1096, TP=154]]\n",
            "   Accuracy: 89.18%, TPR: 12.32%, TNR: 93.13%\n",
            "Noise 20% - Iteration 1: Oversampled class distribution: [1956 1956]\n",
            "Noise 20% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=21704, FP=2596], [FN=1035, TP=215]]\n",
            "   Accuracy: 85.79%, TPR: 17.20%, TNR: 89.32%\n",
            "Noise 25% - Iteration 1: Oversampled class distribution: [1838 1838]\n",
            "Noise 25% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=20562, FP=3738], [FN=970, TP=280]]\n",
            "   Accuracy: 81.57%, TPR: 22.40%, TNR: 84.62%\n",
            "Noise 30% - Iteration 1: Oversampled class distribution: [1720 1720]\n",
            "Noise 30% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=19205, FP=5095], [FN=914, TP=336]]\n",
            "   Accuracy: 76.48%, TPR: 26.88%, TNR: 79.03%\n",
            "Noise 35% - Iteration 1: Oversampled class distribution: [1603 1603]\n",
            "Noise 35% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=17710, FP=6590], [FN=841, TP=409]]\n",
            "   Accuracy: 70.92%, TPR: 32.72%, TNR: 72.88%\n",
            "Noise 40% - Iteration 1: Oversampled class distribution: [1493 1493]\n",
            "Noise 40% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=16037, FP=8263], [FN=774, TP=476]]\n",
            "   Accuracy: 64.63%, TPR: 38.08%, TNR: 66.00%\n",
            "\n",
            "=== Model: Naive Bayes ===\n",
            "Noise 0% - Iteration 1: Oversampled class distribution: [2430 2430]\n",
            "Noise 0% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=5625, FP=18675], [FN=9, TP=1241]]\n",
            "   Accuracy: 26.87%, TPR: 99.28%, TNR: 23.15%\n",
            "Noise 5% - Iteration 1: Oversampled class distribution: [2311 2311]\n",
            "Noise 5% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=6628, FP=17672], [FN=105, TP=1145]]\n",
            "   Accuracy: 30.42%, TPR: 91.60%, TNR: 27.28%\n",
            "Noise 10% - Iteration 1: Oversampled class distribution: [2191 2191]\n",
            "Noise 10% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=5560, FP=18740], [FN=77, TP=1173]]\n",
            "   Accuracy: 26.35%, TPR: 93.84%, TNR: 22.88%\n",
            "Noise 15% - Iteration 1: Oversampled class distribution: [2065 2065]\n",
            "Noise 15% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=11842, FP=12458], [FN=237, TP=1013]]\n",
            "   Accuracy: 50.31%, TPR: 81.04%, TNR: 48.73%\n",
            "Noise 20% - Iteration 1: Oversampled class distribution: [1956 1956]\n",
            "Noise 20% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=14312, FP=9988], [FN=298, TP=952]]\n",
            "   Accuracy: 59.74%, TPR: 76.16%, TNR: 58.90%\n",
            "Noise 25% - Iteration 1: Oversampled class distribution: [1838 1838]\n",
            "Noise 25% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=11796, FP=12504], [FN=269, TP=981]]\n",
            "   Accuracy: 50.01%, TPR: 78.48%, TNR: 48.54%\n",
            "Noise 30% - Iteration 1: Oversampled class distribution: [1720 1720]\n",
            "Noise 30% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=11067, FP=13233], [FN=301, TP=949]]\n",
            "   Accuracy: 47.03%, TPR: 75.92%, TNR: 45.54%\n",
            "Noise 35% - Iteration 1: Oversampled class distribution: [1603 1603]\n",
            "Noise 35% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=12679, FP=11621], [FN=399, TP=851]]\n",
            "   Accuracy: 52.95%, TPR: 68.08%, TNR: 52.18%\n",
            "Noise 40% - Iteration 1: Oversampled class distribution: [1493 1493]\n",
            "Noise 40% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=10589, FP=13711], [FN=386, TP=864]]\n",
            "   Accuracy: 44.83%, TPR: 69.12%, TNR: 43.58%\n",
            "\n",
            "=== Model: K-Nearest Neighbors ===\n",
            "Noise 0% - Iteration 1: Oversampled class distribution: [2430 2430]\n",
            "Noise 0% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=21592, FP=2708], [FN=928, TP=322]]\n",
            "   Accuracy: 85.77%, TPR: 25.76%, TNR: 88.86%\n",
            "Noise 5% - Iteration 1: Oversampled class distribution: [2311 2311]\n",
            "Noise 5% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=18632, FP=5668], [FN=804, TP=446]]\n",
            "   Accuracy: 74.67%, TPR: 35.68%, TNR: 76.67%\n",
            "Noise 10% - Iteration 1: Oversampled class distribution: [2191 2191]\n",
            "Noise 10% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=16090, FP=8210], [FN=688, TP=562]]\n",
            "   Accuracy: 65.17%, TPR: 44.96%, TNR: 66.21%\n",
            "Noise 15% - Iteration 1: Oversampled class distribution: [2065 2065]\n",
            "Noise 15% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=14468, FP=9832], [FN=626, TP=624]]\n",
            "   Accuracy: 59.07%, TPR: 49.92%, TNR: 59.54%\n",
            "Noise 20% - Iteration 1: Oversampled class distribution: [1956 1956]\n",
            "Noise 20% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13805, FP=10495], [FN=617, TP=633]]\n",
            "   Accuracy: 56.51%, TPR: 50.64%, TNR: 56.81%\n",
            "Noise 25% - Iteration 1: Oversampled class distribution: [1838 1838]\n",
            "Noise 25% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13397, FP=10903], [FN=612, TP=638]]\n",
            "   Accuracy: 54.93%, TPR: 51.04%, TNR: 55.13%\n",
            "Noise 30% - Iteration 1: Oversampled class distribution: [1720 1720]\n",
            "Noise 30% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13252, FP=11048], [FN=608, TP=642]]\n",
            "   Accuracy: 54.38%, TPR: 51.36%, TNR: 54.53%\n",
            "Noise 35% - Iteration 1: Oversampled class distribution: [1603 1603]\n",
            "Noise 35% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=12898, FP=11402], [FN=638, TP=612]]\n",
            "   Accuracy: 52.88%, TPR: 48.96%, TNR: 53.08%\n",
            "Noise 40% - Iteration 1: Oversampled class distribution: [1493 1493]\n",
            "Noise 40% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=12686, FP=11614], [FN=618, TP=632]]\n",
            "   Accuracy: 52.13%, TPR: 50.56%, TNR: 52.21%\n",
            "\n",
            "=== Model: Support Vector Machine ===\n",
            "Noise 0% - Iteration 1: Oversampled class distribution: [2430 2430]\n",
            "Noise 0% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=19309, FP=4991], [FN=541, TP=709]]\n",
            "   Accuracy: 78.35%, TPR: 56.72%, TNR: 79.46%\n",
            "Noise 5% - Iteration 1: Oversampled class distribution: [2311 2311]\n",
            "Noise 5% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=17945, FP=6355], [FN=501, TP=749]]\n",
            "   Accuracy: 73.17%, TPR: 59.92%, TNR: 73.85%\n",
            "Noise 10% - Iteration 1: Oversampled class distribution: [2191 2191]\n",
            "Noise 10% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=16698, FP=7602], [FN=459, TP=791]]\n",
            "   Accuracy: 68.45%, TPR: 63.28%, TNR: 68.72%\n",
            "Noise 15% - Iteration 1: Oversampled class distribution: [2065 2065]\n",
            "Noise 15% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=15785, FP=8515], [FN=483, TP=767]]\n",
            "   Accuracy: 64.78%, TPR: 61.36%, TNR: 64.96%\n",
            "Noise 20% - Iteration 1: Oversampled class distribution: [1956 1956]\n",
            "Noise 20% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=15061, FP=9239], [FN=459, TP=791]]\n",
            "   Accuracy: 62.04%, TPR: 63.28%, TNR: 61.98%\n",
            "Noise 25% - Iteration 1: Oversampled class distribution: [1838 1838]\n",
            "Noise 25% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=14375, FP=9925], [FN=523, TP=727]]\n",
            "   Accuracy: 59.11%, TPR: 58.16%, TNR: 59.16%\n",
            "Noise 30% - Iteration 1: Oversampled class distribution: [1720 1720]\n",
            "Noise 30% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=14280, FP=10020], [FN=549, TP=701]]\n",
            "   Accuracy: 58.63%, TPR: 56.08%, TNR: 58.77%\n",
            "Noise 35% - Iteration 1: Oversampled class distribution: [1603 1603]\n",
            "Noise 35% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13455, FP=10845], [FN=552, TP=698]]\n",
            "   Accuracy: 55.39%, TPR: 55.84%, TNR: 55.37%\n",
            "Noise 40% - Iteration 1: Oversampled class distribution: [1493 1493]\n",
            "Noise 40% => Confusion Matrix Sum (10 runs):\n",
            "   [[TN=13062, FP=11238], [FN=589, TP=661]]\n",
            "   Accuracy: 53.71%, TPR: 52.88%, TNR: 53.75%\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Script to analyze label noise effects on stroke dataset using Random Oversampling:\n",
        " - Maintains the original Accuracy metric\n",
        " - Computes TPR (Sensitivity) and TNR (Specificity)\n",
        " - Prints summed Confusion Matrices for each noise level (over 10 runs)\n",
        " - Generates grouped bar plots vs. Percentage of Labels Correctly Classified\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. SETUP AND DATA LOADING\n",
        "# ---------------------------------------------------------------------\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "\n",
        "model_colors = {\n",
        "    'Logistic Regression': 'blue',\n",
        "    'Decision Tree': 'green',\n",
        "    'Random Forest': 'orange',\n",
        "    'Naive Bayes': 'purple',\n",
        "    'K-Nearest Neighbors': 'brown',\n",
        "    'Support Vector Machine': 'red'\n",
        "}\n",
        "\n",
        "print(\"Loading stroke dataset...\")\n",
        "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
        "\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nMissing Values in Each Column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['bmi'] = imputer.fit_transform(df[['bmi']])\n",
        "\n",
        "# Drop rows with gender as 'Other' (if any)\n",
        "df = df[df['gender'] != 'Other']\n",
        "\n",
        "# One-hot encoding of categorical features\n",
        "categorical_features = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
        "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Prepare feature matrix X and target vector y\n",
        "X = df.drop(['id', 'stroke'], axis=1)\n",
        "y = df['stroke'].astype(int)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_features = ['age', 'avg_glucose_level', 'bmi']\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
        "\n",
        "# Convert to NumPy arrays for further processing\n",
        "X_np = X.values\n",
        "y_np = y.values\n",
        "\n",
        "# Display class distribution\n",
        "print(\"\\nClass Distribution in Original Dataset:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "\n",
        "def compute_metrics_from_confusion(tn, fp, fn, tp):\n",
        "    \"\"\"\n",
        "    Given TN, FP, FN, TP, compute Accuracy, TPR (Sensitivity), and TNR (Specificity).\n",
        "    Returns metrics in percentages.\n",
        "    \"\"\"\n",
        "    total = tn + fp + fn + tp\n",
        "    if total == 0:\n",
        "        return 0, 0, 0\n",
        "    accuracy = (tp + tn) / total\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    return accuracy * 100.0, tpr * 100.0, tnr * 100.0\n",
        "\n",
        "def plot_metric_sorted(dataset_name, metric_name, metric_data, x_labels):\n",
        "    \"\"\"\n",
        "    Plots a grouped bar chart for a given dataset and metric.\n",
        "    Models are sorted by their baseline performance (i.e. at 0% noise, corresponding to 100% correct labels).\n",
        "    \"\"\"\n",
        "\n",
        "    sorted_models = sorted(metric_data.keys(), key=lambda m: metric_data[m][0], reverse=True)\n",
        "    n_models = len(sorted_models)\n",
        "    n_groups = len(x_labels)\n",
        "    x = np.arange(n_groups)\n",
        "    bar_width = 0.12\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i, model in enumerate(sorted_models):\n",
        "        plt.bar(\n",
        "            x + i * bar_width,\n",
        "            metric_data[model],\n",
        "            width=bar_width,\n",
        "            color=model_colors.get(model, 'grey'),\n",
        "            label=model\n",
        "        )\n",
        "\n",
        "    plt.xlabel('% Accurate Labels (Descending)')\n",
        "    plt.ylabel(f'{metric_name} (%)')\n",
        "    plt.title(f'{dataset_name} - {metric_name} vs. % Accurate Labels\\n(Models sorted by baseline performance)')\n",
        "    plt.xticks(x + (n_models / 2 - 0.5) * bar_width, x_labels)\n",
        "    plt.ylim(0, 100)\n",
        "    plt.legend(title='Model')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3. DEFINE MODELS AND SETUP THE NOISE LEVELS FOR ANALYSIS\n",
        "# ---------------------------------------------------------------------\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Support Vector Machine': SVC(probability=True, random_state=RANDOM_STATE, class_weight='balanced')\n",
        "}\n",
        "\n",
        "# Noise levels: from 0% to 40% label noise (0% noise = 100% correct labels)\n",
        "noise_levels = np.arange(0.0, 0.45, 0.05)\n",
        "\n",
        "# Dictionaries to store metrics for each model\n",
        "acc_results = {m: [] for m in models.keys()}\n",
        "tpr_results = {m: [] for m in models.keys()}\n",
        "tnr_results = {m: [] for m in models.keys()}\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4. TRAINING, EVALUATION, AND METRIC COMPUTATION UNDER NOISE\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\nEvaluating each model under different noise levels (10 runs each)...\")\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n=== Model: {model_name} ===\")\n",
        "    for noise_level in noise_levels:\n",
        "        sum_tn, sum_fp, sum_fn, sum_tp = 0, 0, 0, 0\n",
        "\n",
        "        for iteration in range(10):\n",
        "            seed = RANDOM_STATE + iteration\n",
        "\n",
        "            # 50/50 train/test split with stratification\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_np, y_np, test_size=0.5, stratify=y_np, random_state=seed\n",
        "            )\n",
        "\n",
        "            # Introduce label noise in the training set by flipping a fraction of labels\n",
        "            y_train_noisy = y_train.copy()\n",
        "            num_noisy = int(noise_level * len(y_train_noisy))\n",
        "            np.random.seed(seed)\n",
        "            noisy_indices = np.random.choice(len(y_train_noisy), size=num_noisy, replace=False)\n",
        "            y_train_noisy[noisy_indices] = 1 - y_train_noisy[noisy_indices]\n",
        "\n",
        "            # Apply Random Oversampling to balance the training data\n",
        "            ros = RandomOverSampler(random_state=seed)\n",
        "            X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train_noisy)\n",
        "            if iteration == 0:\n",
        "                print(f\"Noise {int(noise_level*100)}% - Iteration {iteration+1}: \",\n",
        "                      np.bincount(y_train_bal))\n",
        "\n",
        "            # Train the model on the balanced data\n",
        "            model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "            # Predict on the test set\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Compute confusion matrix components\n",
        "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=[0, 1]).ravel()\n",
        "            sum_tn += tn\n",
        "            sum_fp += fp\n",
        "            sum_fn += fn\n",
        "            sum_tp += tp\n",
        "\n",
        "        ACC, TPR, TNR = compute_metrics_from_confusion(sum_tn, sum_fp, sum_fn, sum_tp)\n",
        "        acc_results[model_name].append(ACC)\n",
        "        tpr_results[model_name].append(TPR)\n",
        "        tnr_results[model_name].append(TNR)\n",
        "\n",
        "        print(f\"Noise {int(noise_level*100)}% => Confusion Matrix Sum (10 runs):\")\n",
        "        print(f\"   [[TN={sum_tn}, FP={sum_fp}], [FN={sum_fn}, TP={sum_tp}]]\")\n",
        "        print(f\"   Accuracy: {ACC:.2f}%, TPR: {TPR:.2f}%, TNR: {TNR:.2f}%\")"
      ]
    }
  ]
}